{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Effects of Social Media Bots on the Cryptomarket: Sentiment Classification\n",
    "\n",
    "*By Daniel Deutsch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import ssl\n",
    "import string\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             roc_auc_score, roc_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Creates a default https context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Matplotlib styles\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (15, 6),\n",
    "    'axes.prop_cycle': plt.cycler(color=['#4C72B0', '#C44E52', '#55A868', '#8172B2', '#CCB974', '#64B5CD']),\n",
    "    'axes.facecolor': '#EAEAF2'\n",
    "})\n",
    "\n",
    "# Constants\n",
    "START_DATE = datetime(2019, 6, 1)\n",
    "END_DATE = datetime(2022, 6, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Based Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twits = pd.read_csv(\"./datasets/enhanced/twits.csv.gz\", index_col=0, parse_dates=['date'], low_memory=False)\n",
    "df_users = pd.read_csv(\"./datasets/enhanced/users.csv.gz\", index_col=0, parse_dates=['join_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects only useful columns\n",
    "df_small = df_twits[['id', 'user.type', 'base_asset', 'text', 'label']].dropna()\n",
    "\n",
    "# Drop duplicates on text (same twit can tag multiple sabe_asset)\n",
    "df_small.drop_duplicates('text', ignore_index=True, inplace=True)\n",
    "\n",
    "# Bots removal\n",
    "df_small = df_small[df_small['user.type'] == 'User']\n",
    "\n",
    "# Gets a small sample of the dataset for training and testing (balanced labels and base_assets)\n",
    "df_small = df_small.groupby('base_asset', group_keys=False).apply(lambda x: x.groupby('label', group_keys=False).apply(lambda y: y.sample(x['label'].value_counts().min())))\n",
    "\n",
    "# Resets the index\n",
    "df_small.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the explanatory and explanable variables\n",
    "X = df_small[['text', 'text_light_clean', 'text_heavy_clean']]\n",
    "y = df_small['label'].replace({'Bearish': 0, 'Bullish': 1})\n",
    "\n",
    "# Splits the data into train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.9, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the input of the Neural Network\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "\n",
    "# Obtains the output of the Neural Network\n",
    "output = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", name='preprocessing')(text_input)\n",
    "output = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/2\", trainable=True, name='BERT_encoder')(output)\n",
    "output = tf.keras.layers.Dropout(0.6)(output['sequence_output'])\n",
    "output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(output)\n",
    "output = tf.keras.layers.Attention(name='attention')([output, output])\n",
    "output = tf.keras.layers.Conv1D(128, 9, activation='relu', padding='same', name='convolutional')(output)\n",
    "output = tf.keras.layers.GlobalAveragePooling1D(name='average_pooling')(output)\n",
    "output = tf.keras.layers.Dropout(0.4)(output)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(output)\n",
    "\n",
    "# Defines the optimizer of the Neural Network\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Defines the loss function of the Neural Network\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "# Builds and compiles the model\n",
    "model = tf.keras.Model(inputs=text_input, outputs=output)\n",
    "model.compile(optimizer, loss=loss, metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets training params\n",
    "epochs = 30\n",
    "batch_size = 512\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"./models/bert/weights.h5\", monitor='val_accuracy', save_freq='epoch', save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.CSVLogger(\"./models/bert/history.csv\", separator=',', append=True)\n",
    "]\n",
    "\n",
    "# Trains the model\n",
    "history = model.fit(\n",
    "    x=X_train['text'], y=y_train,\n",
    "    validation_data=(X_val['text'], y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Saves the model\n",
    "model.save(\"./models/bert\")\n",
    "\n",
    "# Loads the saved variables\n",
    "model = tf.keras.models.load_model(\"./models/bert\")\n",
    "history = pd.read_csv(\"./models/bert/history.csv\", index_col=0)\n",
    "\n",
    "# Display the history\n",
    "clear_output()\n",
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
